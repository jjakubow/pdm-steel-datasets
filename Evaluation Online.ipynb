{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c198f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# define g-mean score\n",
    "def gmean_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # recall\n",
    "    specificity = tn / (tn + fp)\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941bf0a",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc9ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(no: int, train_size: float = 0.6, scale=True):\n",
    "    df = pd.read_csv(rf\"data\\tcm5_dataset_{no}.csv\")\n",
    "\n",
    "    X = df.loc[:, :\"motor_power_5\"]\n",
    "    Y = df.loc[:, \"Anomaly_Reduction\":]\n",
    "\n",
    "    X_train, X_test_val, Y_train, Y_test_val = train_test_split(X, Y, train_size=train_size, shuffle=False)\n",
    "    X_test, X_val, Y_test, Y_val = train_test_split(X_test_val, Y_test_val, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    X_val = X_val.values\n",
    "    Y_train = Y_train.values\n",
    "    Y_test = Y_test.values\n",
    "    Y_val = Y_val.values\n",
    "\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "    data = {\n",
    "        \"X\": {\n",
    "            \"train\": X_train,\n",
    "            \"test\": X_test,\n",
    "            \"val\": X_val,\n",
    "            \"columns\": X.columns\n",
    "        },\n",
    "        \"Y\": {\n",
    "            \"train\": Y_train,\n",
    "            \"test\": Y_test,\n",
    "            \"val\": Y_val,\n",
    "            \"columns\": Y.columns\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78845539",
   "metadata": {},
   "source": [
    "### RiverML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb590d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.anomaly import HalfSpaceTrees, LocalOutlierFactor, OneClassSVM\n",
    "from river.cluster import KMeans\n",
    "from river import stream\n",
    "\n",
    "class KMeansWrapper:\n",
    "    def __init__(self, **params):\n",
    "        self.model = KMeans(**params)\n",
    "    \n",
    "    def learn_one(self, x):\n",
    "        self.model.learn_one(x)\n",
    "    \n",
    "    def score_one(self, x):\n",
    "        y_cluster = self.model.predict_one(x)\n",
    "        cluster_center = self.model.centers[y_cluster]\n",
    "        cluster_center = np.array(list(cluster_center.values()))\n",
    "        x_array = np.array(list(x.values()))\n",
    "        distance = np.sum((x_array-cluster_center)**2)\n",
    "        \n",
    "        return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aaa0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_dict(x):\n",
    "    return {f\"X{n}\": x[n] for n in range(len(x))}\n",
    "\n",
    "def get_best_threshold_quantile(y_true, anomaly_score, q_min=0.7, q_max=1.0):\n",
    "    qs = []\n",
    "    f1s = []\n",
    "    for q in np.linspace(q_min, q_max, 100):\n",
    "        anomaly_threshold = np.quantile(anomaly_score, q)\n",
    "        y_pred = anomaly_score > anomaly_threshold\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        qs.append(q)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    best_qi = np.argmax(f1s)\n",
    "\n",
    "    return qs[best_qi]\n",
    "\n",
    "def tune_model_river(model_class, data, params_space, max_evals=10, sample=None):\n",
    "    from tqdm.notebook import tqdm\n",
    "    def objective(params: dict):\n",
    "        if sample is None:\n",
    "            X_train = data[\"X\"][\"train\"]\n",
    "            X_test = data['X']['test']\n",
    "            y_true_test = data[\"Y\"][\"test\"].any(axis=1)\n",
    "        else:\n",
    "            n = int(1/sample)\n",
    "            X_train = data[\"X\"][\"train\"][::n]\n",
    "            X_test = data['X']['test'][::n]\n",
    "            y_true_test = data[\"Y\"][\"test\"].any(axis=1)[::n]\n",
    "\n",
    "        model = model_class(**params)\n",
    "        \n",
    "        for i in range(X_train.shape[0]):\n",
    "            x = X_train[i]\n",
    "            x_dict = array_to_dict(x)\n",
    "            model.learn_one(x_dict)\n",
    "        \n",
    "        y_score_test = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            x = X_test[i]\n",
    "            x_dict = array_to_dict(x)\n",
    "            score = model.score_one(x_dict)\n",
    "            y_score_test.append(score)\n",
    "            model.learn_one(x_dict)\n",
    "\n",
    "        pr_auc = average_precision_score(y_true_test, y_score_test)\n",
    "\n",
    "        return -pr_auc\n",
    "    \n",
    "    tpe_algo = hyperopt.tpe.suggest\n",
    "    tpe_trials = hyperopt.Trials()\n",
    "    tpe_best = hyperopt.fmin(fn=objective, space=params_space,  algo=tpe_algo, trials=tpe_trials,  max_evals=max_evals)\n",
    "    best_hp = hyperopt.space_eval(params_space, tpe_best)\n",
    "    \n",
    "    return best_hp\n",
    "\n",
    "\n",
    "def validate_model_river(model_class, data, params={}, sample=None):\n",
    "    if sample is None:\n",
    "        X_train = data[\"X\"][\"train\"]\n",
    "        X_test = data['X']['test']\n",
    "        X_val = data['X']['val']\n",
    "        y_true_test = data[\"Y\"][\"test\"].any(axis=1)\n",
    "        y_true_val = data[\"Y\"][\"val\"].any(axis=1)\n",
    "    else:\n",
    "        n = int(1/sample)\n",
    "        X_train = data[\"X\"][\"train\"][::n]\n",
    "        X_test = data['X']['test'][::n]\n",
    "        X_val = data['X']['val'][::n]\n",
    "        y_true_test = data[\"Y\"][\"test\"].any(axis=1)[::n]\n",
    "        y_true_val = data[\"Y\"][\"val\"].any(axis=1)[::n]\n",
    "\n",
    "    model = model_class(**params)\n",
    "\n",
    "    # model learning on TRAIN dataset\n",
    "    for i in range(X_train.shape[0]):\n",
    "        x = X_train[i]\n",
    "        x_dict = array_to_dict(x)\n",
    "        model.learn_one(x_dict)\n",
    "        \n",
    "    y_score_test = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        x = X_test[i]\n",
    "        x_dict = array_to_dict(x)\n",
    "        score = model.score_one(x_dict)\n",
    "        y_score_test.append(score)\n",
    "        model.learn_one(x_dict)\n",
    "    \n",
    "    # use TEST dataset to estimate best quantile threshold\n",
    "    q_threshold = get_best_threshold_quantile(y_true_test, y_score_test)\n",
    "    anomaly_threshold = np.quantile(y_score_test, q_threshold)\n",
    "    \n",
    "    y_score_val = []\n",
    "    for i in range(X_val.shape[0]):\n",
    "        x = X_val[i]\n",
    "        x_dict = array_to_dict(x)\n",
    "        score = model.score_one(x_dict)\n",
    "        y_score_val.append(score)\n",
    "        model.learn_one(x_dict)\n",
    "\n",
    "    # esitmate metrics on VAL dataset\n",
    "    \n",
    "    predicted_labels = y_score_val > anomaly_threshold\n",
    "    f1 = f1_score(y_true_val, predicted_labels)\n",
    "    pr_auc = average_precision_score(y_true_val, y_score_val)\n",
    "    roc_auc = roc_auc_score(y_true_val, y_score_val)\n",
    "    g_mean = gmean_score(y_true_val, predicted_labels)\n",
    "    \n",
    "    return {\"F1\": f1, \"AUCPR\": pr_auc, 'AUCROC': roc_auc, 'G-mean': g_mean}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d4ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_online_with_params_space = {}\n",
    "\n",
    "models_online_with_params_space[\"KMneas_o\"] = (\n",
    "    KMeansWrapper,\n",
    "    {\n",
    "        'n_clusters': scope.int(hyperopt.hp.uniform('n_clusters', 2, 30)),\n",
    "        'halflife': hyperopt.hp.uniform('halflife', 0, 1),\n",
    "        'mu': hyperopt.hp.uniform('mu', -1, 1),\n",
    "        'sigma': hyperopt.hp.uniform('sigma', 0, 3),\n",
    "        'seed': hyperopt.hp.choice('seed', [42]),\n",
    "    }\n",
    ")\n",
    "\n",
    "models_online_with_params_space['HST_o'] = (\n",
    "    HalfSpaceTrees,\n",
    "    {\n",
    "        'n_trees': scope.int(hyperopt.hp.uniform('n_trees', 10, 500)),\n",
    "        'window_size': scope.int(hyperopt.hp.uniform('window_size', 200, 800)),\n",
    "        'height': scope.int(hyperopt.hp.uniform('height', 3, 10)),\n",
    "        'seed': hyperopt.hp.choice('seed', [42]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# very slow\n",
    "# models_online_with_params_space[\"LOF_o\"] = (\n",
    "#     LocalOutlierFactor, \n",
    "#     {\n",
    "#         'n_neighbors': scope.int(hyperopt.hp.uniform('n_neighbors', 3, 10)),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "models_online_with_params_space[\"OCSVM_o\"] = (\n",
    "    OneClassSVM, \n",
    "    {\n",
    "        'nu': hyperopt.hp.uniform('nu', 0.0001, 0.3),\n",
    "        'intercept_lr': hyperopt.hp.uniform('intercept_lr', 0.001, 0.3),\n",
    "    }\n",
    ")\n",
    "\n",
    "df_results_online = pd.DataFrame()\n",
    "\n",
    "for SELECTED_DATASET in (1, 2,3, 4, 5, 6):\n",
    "    data = read_dataset(SELECTED_DATASET)\n",
    "    df_results_online = pd.DataFrame()\n",
    "    for model_name, model_params in models_online_with_params_space.items():\n",
    "        model_class, params_dict = model_params\n",
    "        print(f\"Tuning {model_name}\")\n",
    "        best_hp = tune_model_river(model_class, data, params_dict, max_evals=200)\n",
    "        print(\"BEST HP:\", best_hp)\n",
    "        res = validate_model_river(model_class, data, best_hp)\n",
    "        for metric_name, metric_value in res.items():\n",
    "            df_results_online.at[model_name, metric_name] = metric_value\n",
    "\n",
    "    print(f\"SELECTED_DATASET: {SELECTED_DATASET}\")\n",
    "    print(df_results_online.round(3))\n",
    "    df_results_online.to_csv(f\"Evaluation_{SELECTED_DATASET}_online3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
