{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87c198f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, average_precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# define g-mean score\n",
    "def gmean_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)  # recall\n",
    "    specificity = tn / (tn + fp)\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941bf0a",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fc9ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(no: int, train_size: float = 0.6, scale=True):\n",
    "    df = pd.read_csv(rf\"data\\tcm5_dataset_{no}.csv\")\n",
    "\n",
    "    X = df.loc[:, :\"motor_power_5\"]\n",
    "    Y = df.loc[:, \"Anomaly_Reduction\":]\n",
    "\n",
    "    X_train, X_test_val, Y_train, Y_test_val = train_test_split(X, Y, train_size=train_size, shuffle=False)\n",
    "    X_test, X_val, Y_test, Y_val = train_test_split(X_test_val, Y_test_val, test_size=0.5, shuffle=False)\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    X_val = X_val.values\n",
    "    Y_train = Y_train.values\n",
    "    Y_test = Y_test.values\n",
    "    Y_val = Y_val.values\n",
    "\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "    data = {\n",
    "        \"X\": {\n",
    "            \"train\": X_train,\n",
    "            \"test\": X_test,\n",
    "            \"val\": X_val,\n",
    "            \"columns\": X.columns\n",
    "        },\n",
    "        \"Y\": {\n",
    "            \"train\": Y_train,\n",
    "            \"test\": Y_test,\n",
    "            \"val\": Y_val,\n",
    "            \"columns\": Y.columns\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd32942",
   "metadata": {},
   "source": [
    "### PyOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "147c738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.anogan import AnoGAN\n",
    "from pyod.models.lof import LocalOutlierFactor\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "class AutoEncoderWrapper:\n",
    "    # wrapper for training autoencoder\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs[\"hidden_neuron_list\"] = [kwargs['hidden_neuron_1'], kwargs['hidden_neuron_2']]\n",
    "        kwargs.pop('hidden_neuron_1')\n",
    "        kwargs.pop('hidden_neuron_2')\n",
    "\n",
    "        self._model = AutoEncoder(verbose=0, **kwargs)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self._model.fit(X)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self._model.decision_function(X)\n",
    "    \n",
    "class BaselineModel:\n",
    "    def __init__(self, anomaly_ratio=0.05):\n",
    "        self.anomaly_ratio = anomaly_ratio\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return np.random.uniform(0, 1, size=(X.shape[0], ))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a99c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold_quantile(y_true, anomaly_score, q_min=0.7, q_max=1.0):\n",
    "    qs = []\n",
    "    f1s = []\n",
    "    for q in np.linspace(q_min, q_max, 100):\n",
    "        anomaly_threshold = np.quantile(anomaly_score, q)\n",
    "        y_pred = anomaly_score > anomaly_threshold\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        qs.append(q)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    best_qi = np.argmax(f1s)\n",
    "\n",
    "    return qs[best_qi]\n",
    "\n",
    "def tune_model_pyod(model_class, data, params_space, max_evals=10, sample=None):\n",
    "    \n",
    "    def objective(params: dict):\n",
    "        if sample is None:\n",
    "            X_train = data[\"X\"][\"train\"]\n",
    "        else:\n",
    "            n = int(1/sample)\n",
    "            X_train = data[\"X\"][\"train\"][::n]\n",
    "        model = model_class(**params)\n",
    "        model.fit(X_train)\n",
    "\n",
    "        true_labels = data[\"Y\"][\"test\"].any(axis=1)\n",
    "        anomaly_score = model.decision_function(data[\"X\"][\"test\"])\n",
    "        pr_auc = average_precision_score(true_labels, anomaly_score)\n",
    "\n",
    "        return -pr_auc\n",
    "    \n",
    "    tpe_algo = hyperopt.tpe.suggest\n",
    "    tpe_trials = hyperopt.Trials()\n",
    "    tpe_best = hyperopt.fmin(fn=objective, space=params_space,  algo=tpe_algo, trials=tpe_trials,  max_evals=max_evals)\n",
    "    best_hp = hyperopt.space_eval(params_space, tpe_best)\n",
    "\n",
    "    return best_hp\n",
    "\n",
    "\n",
    "def validate_model_pyod(model_class, data, params={}, sample=None):\n",
    "    if sample is None:\n",
    "        X_train = data[\"X\"][\"train\"]\n",
    "    else:\n",
    "        n = int(1/sample)\n",
    "        X_train = data[\"X\"][\"train\"][::n]\n",
    "    # model learning on TRAIN dataset\n",
    "    model = model_class(**params)\n",
    "    model.fit(X_train)\n",
    "    \n",
    "    # use TEST dataset to estimate best quantile threshold\n",
    "    y_true_test = data[\"Y\"][\"test\"].any(axis=1)\n",
    "    anomaly_score_test = model.decision_function(data[\"X\"][\"test\"])\n",
    "    q_threshold = get_best_threshold_quantile(y_true_test, anomaly_score_test)\n",
    "    anomaly_threshold = np.quantile(anomaly_score_test, q_threshold)\n",
    "    \n",
    "    # esitmate metrics on VAL dataset\n",
    "    anomaly_score_val = model.decision_function(data[\"X\"][\"val\"])\n",
    "    y_true_val = data[\"Y\"][\"val\"].any(axis=1)\n",
    "    predicted_labels = anomaly_score_val > anomaly_threshold\n",
    "    f1 = f1_score(y_true_val, predicted_labels)\n",
    "    pr_auc = average_precision_score(y_true_val, anomaly_score_val)\n",
    "    roc_auc = roc_auc_score(y_true_val, anomaly_score_val)\n",
    "    g_mean = gmean_score(y_true_val, predicted_labels)\n",
    "    \n",
    "    return {\"F1\": f1, \"AUCPR\": pr_auc, 'AUCROC': roc_auc, 'G-mean': g_mean}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_params_space = {}\n",
    "\n",
    "# very very slow\n",
    "# models_with_params_space['AnoGAN'] = (\n",
    "#     AnoGAN,\n",
    "#     {\n",
    "#         'epochs':  hyperopt.hp.choice('epochs', [50, 100, 150]),\n",
    "#         'epochs_query':  hyperopt.hp.choice('epochs_query', [5, 10]),\n",
    "#         'G_layers':  hyperopt.hp.choice('G_layers', [[5, 10], [10, 10], [20, 10, 10], [8, 5, 4]]),\n",
    "#         'D_layers':  hyperopt.hp.choice('D_layers', [[10, 5], [8, 5], [20, 10], [12, 6]]),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "models_with_params_space[\"Baseline\"] = (\n",
    "    BaselineModel,\n",
    "    {\n",
    "        # dummy feature\n",
    "        'anomaly_ratio': scope.int(hyperopt.hp.uniform('anomaly_ratio', 0, 1)),\n",
    "    }\n",
    ")\n",
    "\n",
    "models_with_params_space[\"AE\"] = (\n",
    "    AutoEncoderWrapper, \n",
    "    {\n",
    "        'epoch_num':  hyperopt.hp.choice('epoch_num', [5, 10, 20, 30]),\n",
    "        'lr': hyperopt.hp.choice('lr', [0.001, 0.003, 0.005]),\n",
    "        'batch_size': hyperopt.hp.choice('batch_size', [16, 32]),\n",
    "        'hidden_neuron_1': scope.int(hyperopt.hp.uniform('hidden_neuron_1', 32, 129)),\n",
    "        'hidden_neuron_2': scope.int(hyperopt.hp.uniform('hidden_neuron_2', 5, 20)),\n",
    "        }\n",
    ")\n",
    "\n",
    "models_with_params_space[\"PCA\"] = (\n",
    "    PCA,\n",
    "    {\n",
    "        'n_components': scope.int(hyperopt.hp.uniform('n_components', 2, 16)),\n",
    "    }\n",
    ")\n",
    "\n",
    "models_with_params_space[\"IForest\"] = (\n",
    "    IForest, \n",
    "    {\n",
    "        'n_estimators': scope.int(hyperopt.hp.uniform('n_estimators', 10, 500)),\n",
    "        'max_samples': hyperopt.hp.uniform('max_samples', 0.01, 0.3),\n",
    "        'max_features': hyperopt.hp.uniform('max_features', 0.3, 1.0),\n",
    "        'bootstrap': hyperopt.hp.choice('bootstrap', [True, False]),\n",
    "        'n_jobs': hyperopt.hp.choice('n_jobs', [4]),\n",
    "        'random_state': hyperopt.hp.choice('random_state', [44]),\n",
    "    }\n",
    ")\n",
    "\n",
    "models_with_params_space[\"LODA\"] = (\n",
    "    LODA, \n",
    "    {\n",
    "        'n_bins': scope.int(hyperopt.hp.uniform('n_bins', 5, 100)),\n",
    "        'n_random_cuts': scope.int(hyperopt.hp.uniform('n_random_cuts', 10, 500)),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "models_with_params_space[\"OCSVM\"] = (\n",
    "    OCSVM, \n",
    "    {\n",
    "        'kernel': hyperopt.hp.choice('kernel', ['rbf', 'sigmoid', 'linear']),\n",
    "        'nu': hyperopt.hp.uniform('nu', 0.001, 0.3),\n",
    "        'gamma': hyperopt.hp.loguniform('gamma', np.log(1e-5), np.log(1e1)),\n",
    "        'coef0': hyperopt.hp.uniform('coef0', 0.0, 1.0),\n",
    "    }\n",
    ")\n",
    "\n",
    "models_with_params_space[\"HBOS\"] = (\n",
    "    HBOS, \n",
    "    {\n",
    "        'n_bins': scope.int(hyperopt.hp.uniform('n_bins', 5, 100)),\n",
    "        'alpha': hyperopt.hp.uniform('alpha', 0.0, 1),\n",
    "        'tol': hyperopt.hp.uniform('coef0', 0.0, 1.0),\n",
    "    }\n",
    ")\n",
    "\n",
    "for SELECTED_DATASET in (1, 2, 3, 4, 5, 6):\n",
    "    data = read_dataset(SELECTED_DATASET)\n",
    "    \n",
    "    df_results = pd.DataFrame()\n",
    "    for model_name, settings in models_with_params_space.items():\n",
    "        model_class, params_space = settings\n",
    "        print(f\"Tuning {model_name}\")\n",
    "        best_hp = tune_model_pyod(model_class, data, params_space, max_evals=200)\n",
    "        print(\"BEST HP:\", best_hp)\n",
    "        res = validate_model_pyod(model_class, data, best_hp)\n",
    "        for metric_name, metric_value in res.items():\n",
    "            df_results.at[model_name, metric_name] = metric_value\n",
    "    \n",
    "    print(f\"SELECTED_DATASET: {SELECTED_DATASET}\")\n",
    "    print(df_results.round(3))\n",
    "    df_results.to_csv(f\"Evaluation_{SELECTED_DATASET}.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
